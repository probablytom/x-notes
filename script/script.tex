\documentclass[draft]{tufte-handout}
\usepackage[obeyDraft]{todonotes}
\author{Tom Wallis}
\title{Using Anthropomorphic Algorithms}
\date{}
\begin{document}
\maketitle

% What are Anthropomorphic Algorithms?
\section{What are Anthropomorphic Algorithms?}
So I can imagine one or two or many people might want ``anthropomorphic algorithms'' to be explained\ldots{}it's really not as complicated as the name makes it sound!\par

An ``algorithm'' is basically just a piece of software. ``Anthropomorphic'' things are things with human traits. So, when I'm talking about ``anthropomorphic algorithms'', I'm literally just talking about software that represents human behaviour in a computer.\par

A really fun example that I like is the idea of a phone that can see that you're drunk and trying to call your ex at 3 in the morning, and doesn't let you make the call, to save you regretting leaving that voicemail the next day. And the software that would make that work might be called a ``regret formalism'', or a computational model of regret.\par

So an anthropomorphic algorithm is just that. They tend to exist for traits like trust, or comfort, and you can imagine building one for regret or empathy, too. So the research I want to tell you about is my formalism of responsibility, and my talk today is going to be on how we can \emph{use} responsibility formalisms. I hope you find it interesting, because what I want to get across in this talk is that you can almost certainly do cool things in your field with this technology, and it would be great to see people use it in their own research.

% Why should we care?
\section{Why should you care?}
% - Urban Development
\subsection{Urban Development}
To demonstrate: what happens if we develop a city with a sense of ``responsibility''?

%   - A city with an understanding of responsibility for different emergency services

Well, recently we've been building ``smart cities''. A smart city uses a whole bunch of data and technology to make it work better. They might try to ease traffic or make wifi available everywhere for free. That city's got a whole bunch of computers in it...what if we introduce responsibility to them?\par

The city might identify things it was responsible for, like taking bins out when they were full, and discharge that responsibility by sending binmen to the full bins. That's quite efficient: now there's no need for binmen to spend their days doing a route of half-full bins, the city saves money, and we don't have to put up with as much litter.\par

Where responsibility's really interesting is when you use it to identify how responsible \emph{other} people are. So, imagine we built a city which analysed an injury on CCTV and identified whether A\&E or Minor Injuries was more likely to be responsible for treating the patient. Not only could the city contact the emergency services for the patient, but it's sense of \emph{other people's} responsibility also saves time and money.\par

That's a really big deal.\par

% Call to arms
\section{You can help}
% - We need people do *do* this research!
You might notice that this sounds a lot like sci-fi. It \emph{is} a lot like sci-fi. The thing is, as this technology gets better, applications like this are actually really feasible -- and we need people doing the research \emph{now} to make it happen then.\par
% - Lots of geography, psychology & sociology, plus computer science!
Urban development is a strange subject to apply computing science to --- but we've heard from a few speakers from Geography in this conference, and their talks have mostly been urban development. I wonder whether there are any geography students here who can actually think of their own applications, maybe in other fields?\par

% - What would you use this for in *your* field?
The point is: whatever your field is, there's almost \emph{certainly} an application of this technology for you. This goes particularly for the social sciences. One can imagine a hospital with empathy, and what we might be able to do with that. We've heard about responsible cities and regret-saving smartphones.\par

There are weird examples too: did anyone read or watch Hitchhiker's Guide To The Galaxy? There are doors in the series, ``Sirius Cybernetics Corporation's Genuine People Personalities'' doors which delight in opening doors for people. It's kind of strange. But this science fiction can become reality really quickly, so long as you're interested in, say, designing doors. I wish my lamp would take pity on me and not be as bright when I'm hungover. Can someone design a lamp with pity? Please?\par

These aren't jokes, they're reality. And that's kind of cool! But it's not computer scientists that should be making that happen: it's you, the audience. What cool stuff can you make with this tech?

\section{Let's get Nasty}
Here's a conversation I had with my girlfriend recently: I was discussing how a phone with a sense of regret might quietly not send a text to your ex at three in the morning, because it might agree with your friends that you'll \emph{really} regret it in the morning. Her response: ``Whoa\ldots{}that's too far! That's some real 1984 Orwellian stuff: don't you think it's verging on censorship?''\par

\ldots{}and she was right. The thing is, I'd never considered that. Computer scientists \emph{really} shouldn't be developing this stuff. Remember that quote from Jurassic Park? It goes: ``your scientists were so preoccupied with whether or not they could that they didn't stop to think if they should.''\par

I think that's true of a lot of the things computer scientists develop sometimes. The thing is, there's rarely any input from humanities, from social scientists. That's rarely where the money is.\par

Well, here's your chance. If you want to develop something neat, or you want to stop us developing something dumb, ask yourselves how this technology can impact your work. Or, maybe more interestingly, ask yourselves what problems you have day-to-day --- like a blazing hangover --- and ask whether anthropomorphic algorithms can solve that problem. I'll bet everyone in this room can find something to solve with them --- and I hope someone does. 

\bigskip

Thank you. 

% - Philosophy & Existential Risk
%\subsection{Philosophy of Mind / Existential Risk}
%I'll leave one more note, which is on philosophy and rights. 
%   - Philosophy of mind
%     - What does it mean for AI to have human traits?
%I'm not sure what it really means for an AI to have human traits, philosophically.
%     - We can *explore* what it means to be a person with responsible machines
%   - Can we use this for safe AI?
%     - human-like interaction helps communicate
%     - Need research into human corrigibility and the traits that go into it


\end{document}